{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {1: 3, 2: 2, 3: 2, 4: 1}\n",
      "Output: {1: [1, 2, 3], 2: [4, 5], 3: [6, 7], 4: [8]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#here key is layer and value is # of nodes(neuron) for each layer\n",
    "#first is input layer, last is output layer and all remainings are hidden layers\n",
    "layers = {1:3, 2:2, 3:2, 4:1}\n",
    "def createANNDataStructure(layers):\n",
    "  layersWithListOfNodes = {}\n",
    "  rangeEnd = 1\n",
    "  for i in layers:\n",
    "    rangeStart = rangeEnd\n",
    "    rangeEnd = layers[i] + rangeStart \n",
    "    layersWithListOfNodes[i] = list(range(rangeStart,rangeEnd))\n",
    "  return layersWithListOfNodes\n",
    "print(\"Input:\", layers)\n",
    "layers = createANNDataStructure(layers)\n",
    "print(\"Output:\", layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#generates random weight for each node specified in multi layer ann data structure\n",
    "def randomWeightAndBiosGeneratorForNodes(layers):\n",
    "  w = {}\n",
    "  b = {}\n",
    "  if(len(layers) <= 1):\n",
    "    return w\n",
    "  for i in layers:\n",
    "    current = layers[i]\n",
    "    next = {}\n",
    "    if(i+1 in layers):\n",
    "      next = layers[i+1]\n",
    "    for currNode in current:\n",
    "      if(i != 1):\n",
    "        b[currNode] = round(random.uniform(-5, 5), 1)\n",
    "      for nextNode in next:\n",
    "        index =  int(str(currNode) + str(nextNode)) #link between two nodes\n",
    "        w[index] = round(random.uniform(-5, 5), 1)\n",
    "  return w, b\n",
    "weights, bios = randomWeightAndBiosGeneratorForNodes(layers)\n",
    "\n",
    "#generates random features(/input) for input layer specified in multi layer ann data structure\n",
    "def randomFeatureGenerator(inputLayer):\n",
    "  x = {}\n",
    "  for i in inputLayer:\n",
    "    x[i] = round(random.uniform(-5, 5), 1)\n",
    "  return x\n",
    "x = randomFeatureGenerator(layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 0/medium\n",
    "\n",
    "layers: {1: [1, 2, 3], 2: [4, 5], 3: [6, 7], 4: [8]}\n",
    "weights {14: -3.5, 15: 3.8, 24: -4.3, 25: -3.4, 34: -0.1, 35: -2.9, 46: -2.5, 47: -4.9, 56: 4.2, 57: -4.4, 68: -4.6, 78: 1.3}\n",
    "bios/theta: {4: 3.0, 5: 2.9, 6: -2.6, 7: 1.5, 8: 4.1}\n",
    "x/input/features: {1: -0.5, 2: -3.8, 3: 0.9}\n",
    "\n",
    "\n",
    "#sample 1\n",
    "layers = {1: [1, 2, 3], 2: [4, 5], 3: [6, 7], 4: [8]}\n",
    "weights=  {14: 2.1, 15: 2.5, 24: -1.4, 25: 2.7, 34: -1.7, 35: -1.9, \n",
    "        46: -0.2, 47: 2.3, 56: 3.8, 57: 2.3, \n",
    "        68: 0.3, 78: -2.4}\n",
    "bios =  {1: 3.9, 2: -4.0, 3: 1.8, 4: 2.2, 5: -1.8, 6: -0.2, 7: 1.1, 8: 3.6}\n",
    "x = {1: -3.2, 2: 2.5, 3: -4.3}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 0 #medium\n",
    "layers = {1: [1, 2, 3], 2: [4, 5], 3: [6, 7], 4: [8]}\n",
    "weights = {14: -3.5, 15: 3.8, 24: -4.3, 25: -3.4, 34: -0.1, 35: -2.9, 46: -2.5, 47: -4.9, 56: 4.2, 57: -4.4, 68: -4.6, 78: 1.3}\n",
    "bios = {4: 3.0, 5: 2.9, 6: -2.6, 7: 1.5, 8: 4.1}\n",
    "x = {1: -0.5, 2: -3.8, 3: 0.9}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 2\n",
    "layers = {1:[1,2,3], 2:[4, 5], 3: [6]}\n",
    "x = {1:1, 2:0, 3:1}\n",
    "y = 1\n",
    "weights = {14:0.2, 15:-0.3, 24:0.4, 25:0.1, 34:-0.5, 35:0.2, 46:-0.3, 56:-0.2}\n",
    "bios = {4:-0.4, 5: 0.2, 6:0.1} #theta\n",
    "learning_rate = .9 #eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: {1: [1, 2, 3], 2: [4, 5], 3: [6]}\n",
      "weights {14: 0.2, 15: -0.3, 24: 0.4, 25: 0.1, 34: -0.5, 35: 0.2, 46: -0.3, 56: -0.2}\n",
      "bios/theta: {4: -0.4, 5: 0.2, 6: 0.1}\n",
      "x/input/features: {1: 1, 2: 0, 3: 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"layers:\", layers)\n",
    "print(\"weights\", weights) #for all links between nodes\n",
    "print(\"bios/theta:\", bios) # for hidden and output layers\n",
    "print(\"x/input/features:\", x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---node: 4\n",
      "bios/theta: -0.4\n",
      "(w14 * f1) 0.2 * 1 = 0.2\n",
      "(w24 * f2) 0.4 * 0 = 0.0\n",
      "(w34 * f3) -0.5 * 1 = -0.5\n",
      "z is -0.7, a is 0.33\n",
      "\n",
      "---node: 5\n",
      "bios/theta: 0.2\n",
      "(w15 * f1) -0.3 * 1 = -0.3\n",
      "(w25 * f2) 0.1 * 0 = 0.0\n",
      "(w35 * f3) 0.2 * 1 = 0.2\n",
      "z is 0.1, a is 0.52\n",
      "\n",
      "---node: 6\n",
      "bios/theta: 0.1\n",
      "(w46 * f4) -0.3 * 0.33 = -0.099\n",
      "(w56 * f5) -0.2 * 0.52 = -0.10400000000000001\n",
      "z is -0.1, a is 0.48\n",
      "\n",
      "Forward Propagation Result:\n",
      "z: {4: -0.7, 5: 0.1, 6: -0.1}\n",
      "a: {4: 0.33, 5: 0.52, 6: 0.48}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#calcuates z value (part of forward propagration) for given node, weight, features/x values and bios\n",
    "def forwardProp(node, w, f, b):\n",
    "  print(\"\\n---node:\", node)\n",
    "  print(\"bios/theta:\", b)\n",
    "  z = b  \n",
    "  for i in f:\n",
    "    index =  int(str(i) + str(node)) #weight between two nodes\n",
    "    print(\"(w{} * f{}) {} * {} = {}\".format(index, i, w[index], f[i], (w[index] * f[i])))\n",
    "    z = z + (w[index] * f[i])\n",
    "  return round(z, 2)\n",
    "\n",
    "#calcuates sigmoid for z value\n",
    "def sigmoid(z):\n",
    "  a = (1/(1 + math.exp(-z)))\n",
    "  a = round(a, 2)\n",
    "  print(\"z is {}, a is {}\".format(z, a))\n",
    "  return a\n",
    "\n",
    "def calculateZandA(layers, w, b, x):\n",
    "  z = {}\n",
    "  a = {}\n",
    "  nextX = x\n",
    "  for i in range(len(layers) + 1):\n",
    "    tempX = {}\n",
    "    next = {}\n",
    "    if(i+2 in layers): #starts with 2nd layer, 0+2 = 2 = [4,5]\n",
    "      next = layers[i+2]\n",
    "    for nextNode in next:\n",
    "      z[nextNode] = forwardProp(nextNode, w, nextX, bios[nextNode])\n",
    "      a[nextNode] = sigmoid(z[nextNode])\n",
    "      tempX[nextNode] = a[nextNode]\n",
    "    #set features/x for next layer\n",
    "    nextX = tempX\n",
    "  return z, a\n",
    "\n",
    "z,a = calculateZandA(layers, weights, bios, x)\n",
    "print(\"\\nForward Propagation Result:\")\n",
    "print(\"z:\", z) #for hidden and output layers\n",
    "print(\"a:\", a) #for hidden and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y/output/label: 1\n",
      "learning rate/eta: 0.9\n"
     ]
    }
   ],
   "source": [
    "learning_rate = .9 #eta\n",
    "y = 1\n",
    "print(\"y/output/label:\", y)\n",
    "print(\"learning rate/eta:\", learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Propagation - Find Error result:\n",
      "{6: 0.13, 4: -0.01, 5: -0.01}\n"
     ]
    }
   ],
   "source": [
    "def findError(layers, w, a, y):\n",
    "  err = {}\n",
    "  \n",
    "  #find error for output layer\n",
    "  outputLayer = layers[len(layers)]\n",
    "  for i in outputLayer:\n",
    "    err[i] = a[i] * (1 - a[i]) * (y - a[i])\n",
    "    err[i] = round(err[i], 2)\n",
    "  #find error for hidden layers\n",
    "  for i in reversed(layers):\n",
    "    #exclude input layer\n",
    "    if(i == 2):\n",
    "      return err\n",
    "    #layers: {1: [1, 2, 3], 2: [4, 5], 3: [6, 7], 4: [8]}\n",
    "    current = layers[i] #starts with 4 = 4 = 4:[8]\n",
    "    previous = layers[i-1] #starts with 4-1 = 3 = 3:[6,7]\n",
    "    for prevNode in previous:\n",
    "      sumOfWeightAndError = 0\n",
    "      for currNode in current:\n",
    "        index =  int(str(prevNode) + str(currNode)) #link between two nodes\n",
    "        if index in w and currNode in err:\n",
    "          sumOfWeightAndError = sumOfWeightAndError + (w[index] * err[currNode])\n",
    "      err[prevNode] = a[currNode] * (1 - a[currNode]) * sumOfWeightAndError\n",
    "      err[prevNode] = round(err[prevNode], 2)\n",
    "  return err\n",
    "errors = findError(layers, weights, a, y)\n",
    "print(\"Backward Propagation - Find Error result:\")\n",
    "print(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Propagation - new/updated weights and bios:\n",
      "Updated weights: {14: 0.2, 15: -0.3, 24: 0.4, 25: 0.1, 34: -0.5, 35: 0.2, 46: -0.26, 56: -0.14}\n",
      "Updated bios/theta: {4: -0.41, 5: 0.19, 6: 0.22}\n"
     ]
    }
   ],
   "source": [
    "#backward propagation: calculate/Update Weights and Bios depending on error \n",
    "def backwordPropUpdateWeights(layers, w, l, err, a):\n",
    "  nWeight = {}\n",
    "  if(len(layers) <= 1):\n",
    "    return w\n",
    "  for i in range(len(layers)):\n",
    "    current = layers[i+1]\n",
    "    next = {}\n",
    "    if(i+2 in layers):\n",
    "      next = layers[i+2]\n",
    "    for currNode in current:\n",
    "      for nextNode in next:\n",
    "        index =  int(str(currNode) + str(nextNode)) #link between two nodes\n",
    "        #print(index)\n",
    "        if(nextNode not in err):\n",
    "            err[nextNode] = 0\n",
    "        if(currNode not in a):\n",
    "            a[currNode] = 0\n",
    "        nWeight[index] = w[index] + (l * err[nextNode] * a[currNode])\n",
    "        nWeight[index] = round(nWeight[index], 2)\n",
    "  return nWeight\n",
    "new_weights = backwordPropUpdateWeights(layers, weights, learning_rate, errors, a)\n",
    "print(\"Backward Propagation - new/updated weights and bios:\")\n",
    "print(\"Updated weights:\", new_weights)\n",
    "\n",
    "def backwordPropUpdateBios(b, l, err):\n",
    "  nBios = {}\n",
    "  for i in b:\n",
    "    if(i not in err):\n",
    "      err[i] = 0\n",
    "    nBios[i] = b[i] + (l * err[i])\n",
    "    nBios[i] = round(nBios[i], 2)\n",
    "  return nBios\n",
    "\n",
    "new_bios = backwordPropUpdateBios(bios, learning_rate, errors)\n",
    "print(\"Updated bios/theta:\", new_bios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
