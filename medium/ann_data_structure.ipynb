{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6\n",
      "6 9\n",
      "9 13\n",
      "13 14\n",
      "14 15\n",
      "{1: [1, 2, 3, 4, 5], 2: [6, 7, 8], 3: [9, 10, 11, 12], 4: [13], 5: [14]}\n",
      "{1: [1, 2, 3, 4, 5], 2: [6, 7, 8], 3: [9, 10, 11, 12], 4: [13], 5: [14]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         w[index] \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(random\u001b[39m.\u001b[39muniform(\u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m), \u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m layers, w, b\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m allLayers, weights, bios \u001b[39m=\u001b[39m randomWeightAndBiosGeneratorForNodes(allLayers)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m#generates random features(/input) for input layer specified in multi layer ann data structure\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandomFeatureGenerator\u001b[39m(inputLayer):\n",
      "\u001b[1;32m/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandomWeightAndBiosGeneratorForNodes\u001b[39m(layers):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m   layers \u001b[39m=\u001b[39m createAnnDataStructure(layers)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m   w \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m   b \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;32m/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m layers:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   rangeStart \u001b[39m=\u001b[39m rangeEnd\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   rangeEnd \u001b[39m=\u001b[39m layers[i] \u001b[39m+\u001b[39;49m rangeStart \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m   \u001b[39mprint\u001b[39m(rangeStart,rangeEnd)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaushal/dev/deep_learning/medium/ann_data_structure.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m   layersWithListOfNodes[i] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(rangeStart,rangeEnd))\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#here key is layer and value is # of nodes(neuron) for each layer\n",
    "#first is input layer, last is output layer and all remainings are hidden layers\n",
    "layers = {1:5, 2:3, 3:4, 4:1, 5:1}\n",
    "#allLayers = {1:[1,2,3], 2:[4, 5], 3:[6,7], 4:[8,9,10], 5:[11]}\n",
    "def createAnnDataStructure(layers):\n",
    "  layersWithListOfNodes = {}\n",
    "  rangeEnd = 1\n",
    "  for i in layers:\n",
    "    rangeStart = rangeEnd\n",
    "    rangeEnd = layers[i] + rangeStart \n",
    "    layersWithListOfNodes[i] = list(range(rangeStart,rangeEnd))\n",
    "  return layersWithListOfNodes\n",
    "\n",
    "layers = createAnnDataStructure(layers)\n",
    "print(layers)\n",
    "\n",
    "import random\n",
    "#generates random weight for each node specified in multi layer ann data structure\n",
    "def randomWeightAndBiosGeneratorForNodes(layers):\n",
    "  layers = createAnnDataStructure(layers)\n",
    "  w = {}\n",
    "  b = {}\n",
    "  if(len(layers) <= 1):\n",
    "    return w\n",
    "  for i in layers:\n",
    "    current = layers[i]\n",
    "    next = {}\n",
    "    if(i+1 in layers):\n",
    "      next = layers[i+1]\n",
    "    for currNode in current:\n",
    "      b[currNode] = round(random.uniform(1, 100), 2)\n",
    "      for nextNode in next:\n",
    "        index =  int(str(currNode) + str(nextNode)) #link between two nodes\n",
    "        w[index] = round(random.uniform(1, 100), 2)\n",
    "  return layers, w, b\n",
    "allLayers, weights, bios = randomWeightAndBiosGeneratorForNodes(layers)\n",
    "\n",
    "#generates random features(/input) for input layer specified in multi layer ann data structure\n",
    "def randomFeatureGenerator(inputLayer):\n",
    "  x = {}\n",
    "  for i in inputLayer:\n",
    "    x[i] = round(random.uniform(1, 100), 2)\n",
    "  return x\n",
    "x = randomFeatureGenerator(allLayers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {1: 3, 2: 2, 3: 2, 4: 1}\n",
      "Output: {1: [1, 2, 3], 2: [4, 5], 3: [6, 7], 4: [8]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#here key is layer and value is # of nodes(neuron) for each layer\n",
    "#first is input layer, last is output layer and all remainings are hidden layers\n",
    "layers = {1:3, 2:2, 3:2, 4:1}\n",
    "def createANNDataStructure(layers):\n",
    "  layersWithListOfNodes = {}\n",
    "  rangeEnd = 1\n",
    "  for i in layers:\n",
    "    rangeStart = rangeEnd\n",
    "    rangeEnd = layers[i] + rangeStart \n",
    "    layersWithListOfNodes[i] = list(range(rangeStart,rangeEnd))\n",
    "  return layersWithListOfNodes\n",
    "print(\"Input:\", layers)\n",
    "layers = createANNDataStructure(layers)\n",
    "print(\"Output:\", layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#generates random weight for each node specified in multi layer ann data structure\n",
    "def randomWeightAndBiosGeneratorForNodes(layers):\n",
    "  w = {}\n",
    "  b = {}\n",
    "  if(len(layers) <= 1):\n",
    "    return w\n",
    "  for i in layers:\n",
    "    current = layers[i]\n",
    "    next = {}\n",
    "    if(i+1 in layers):\n",
    "      next = layers[i+1]\n",
    "    for currNode in current:\n",
    "      b[currNode] = round(random.uniform(-5, 5), 1)\n",
    "      for nextNode in next:\n",
    "        index =  int(str(currNode) + str(nextNode)) #link between two nodes\n",
    "        w[index] = round(random.uniform(-5, 5), 1)\n",
    "  return w, b\n",
    "weights, bios = randomWeightAndBiosGeneratorForNodes(layers)\n",
    "\n",
    "#generates random features(/input) for input layer specified in multi layer ann data structure\n",
    "def randomFeatureGenerator(inputLayer):\n",
    "  x = {}\n",
    "  for i in inputLayer:\n",
    "    x[i] = round(random.uniform(-5, 5), 1)\n",
    "  return x\n",
    "x = randomFeatureGenerator(layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 1\n",
    "\n",
    "layers = {1: [1, 2, 3], 2: [4, 5], 3: [6, 7], 4: [8]}\n",
    "weights=  {14: 2.1, 15: 2.5, 24: -1.4, 25: 2.7, 34: -1.7, 35: -1.9, \n",
    "        46: -0.2, 47: 2.3, 56: 3.8, 57: 2.3, \n",
    "        68: 0.3, 78: -2.4}\n",
    "bios =  {1: 3.9, 2: -4.0, 3: 1.8, 4: 2.2, 5: -1.8, 6: -0.2, 7: 1.1, 8: 3.6}\n",
    "x = {1: -3.2, 2: 2.5, 3: -4.3}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 2\n",
    "layers = {1:[1,2,3], 2:[4, 5], 3: [6]}\n",
    "x = {1:1, 2:0, 3:1}\n",
    "y = 1\n",
    "weights = {14:0.2, 15:-0.3, 24:0.4, 25:0.1, 34:-0.5, 35:0.2, 46:-0.3, 56:-0.2}\n",
    "bios = {4:-0.4, 5: 0.2, 6:0.1} #theta\n",
    "learning_rate = .9 #eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: {1: [1, 2, 3], 2: [4, 5], 3: [6, 7], 4: [8]}\n",
      "weights {14: 2.1, 15: 2.5, 24: -1.4, 25: 2.7, 34: -1.7, 35: -1.9, 46: -0.2, 47: 2.3, 56: 3.8, 57: 2.3, 68: 0.3, 78: -2.4}\n",
      "bios/theta: {1: 3.9, 2: -4.0, 3: 1.8, 4: 2.2, 5: -1.8, 6: -0.2, 7: 1.1, 8: 3.6}\n",
      "x/input/features: {1: -3.2, 2: 2.5, 3: -4.3}\n"
     ]
    }
   ],
   "source": [
    "print(\"layers:\", layers)\n",
    "print(\"weights\", weights)\n",
    "print(\"bios/theta:\", bios)\n",
    "print(\"x/input/features:\", x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---node: 4\n",
      "bios/theta: 2.2\n",
      "(w14 * f1) 2.1 * -3.2 = -6.720000000000001\n",
      "(w24 * f2) -1.4 * 2.5 = -3.5\n",
      "(w34 * f3) -1.7 * -4.3 = 7.31\n",
      "z is -0.71, a is 0.3295988401911314\n",
      "\n",
      "---node: 5\n",
      "bios/theta: -1.8\n",
      "(w15 * f1) 2.5 * -3.2 = -8.0\n",
      "(w25 * f2) 2.7 * 2.5 = 6.75\n",
      "(w35 * f3) -1.9 * -4.3 = 8.17\n",
      "z is 5.119999999999999, a is 0.9940594778016597\n",
      "\n",
      "---node: 6\n",
      "bios/theta: -0.2\n",
      "(w46 * f4) -0.2 * 0.3295988401911314 = -0.06591976803822629\n",
      "(w56 * f5) 3.8 * 0.9940594778016597 = 3.7774260156463066\n",
      "z is 3.5115062476080805, a is 0.9710133896826679\n",
      "\n",
      "---node: 7\n",
      "bios/theta: 1.1\n",
      "(w47 * f4) 2.3 * 0.3295988401911314 = 0.7580773324396022\n",
      "(w57 * f5) 2.3 * 0.9940594778016597 = 2.2863367989438173\n",
      "z is 4.144414131383419, a is 0.9843946661582312\n",
      "\n",
      "---node: 8\n",
      "bios/theta: 3.6\n",
      "(w68 * f6) 0.3 * 0.9710133896826679 = 0.29130401690480034\n",
      "(w78 * f7) -2.4 * 0.9843946661582312 = -2.362547198779755\n",
      "z is 1.5287568181250455, a is 0.8218243490503263\n",
      "\n",
      "\n",
      "STEP 1: Forward Propagation Result:\n",
      "z: {4: -0.71, 5: 5.119999999999999, 6: 3.5115062476080805, 7: 4.144414131383419, 8: 1.5287568181250455}\n",
      "a: {4: 0.3295988401911314, 5: 0.9940594778016597, 6: 0.9710133896826679, 7: 0.9843946661582312, 8: 0.8218243490503263}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#calcuates z value (part of forward propogration) for given node, weight, features/x values and bios\n",
    "def forwardProp(node, w, f, b):\n",
    "  print(\"\\n---node:\", node)\n",
    "  print(\"bios/theta:\", b)\n",
    "  z = b  \n",
    "  for i in f:\n",
    "    index =  int(str(i) + str(node)) #weight between two nodes\n",
    "    print(\"(w{} * f{}) {} * {} = {}\".format(index, i, w[index], f[i], (w[index] * f[i])))\n",
    "    z = z + (w[index] * f[i])\n",
    "  return z\n",
    "\n",
    "#calcuates sigmoid for z value\n",
    "def sigmoid(z):\n",
    "    a = (1/(1 + math.exp(-z)))\n",
    "    print(\"z is {}, a is {}\".format(z, a))\n",
    "    return a\n",
    "\n",
    "def calculateZandA(layers, w, b, x):\n",
    "  z = {}\n",
    "  a = {}\n",
    "  nextX = x\n",
    "  for i in range(len(layers) + 1):\n",
    "    tempX = {}\n",
    "    next = {}\n",
    "    if(i+2 in layers): #starts with 2nd layer, 0+2 = 2 = [4,5]\n",
    "      next = layers[i+2]\n",
    "    for nextNode in next:\n",
    "      z[nextNode] = forwardProp(nextNode, w, nextX, bios[nextNode])\n",
    "      a[nextNode] = sigmoid(z[nextNode])\n",
    "      tempX[nextNode] = a[nextNode]\n",
    "    #set features/x for next layer\n",
    "    nextX = tempX\n",
    "  return z, a\n",
    "\n",
    "z,a = calculateZandA(layers, weights, bios, x)\n",
    "print(\"\\n\\nSTEP 1: Forward Propagation Result:\")\n",
    "print(\"z:\", z)\n",
    "print(\"a:\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y/output/label: 1.5\n",
      "learning rate/eta: 0.9\n"
     ]
    }
   ],
   "source": [
    "learning_rate = .9 #eta\n",
    "y = 1.5\n",
    "print(\"y/output/label:\", y)\n",
    "print(\"learning rate/eta:\", learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Backward Propagation Find Error result:\n",
      "Error: {8: 0.09930464231538026, 6: 0.004362326473197463, 7: -0.0348986117855797}\n"
     ]
    }
   ],
   "source": [
    "def findError(layers, w, a, y):\n",
    "  err = {}\n",
    "  #find error for output layer\n",
    "  outputLayer = layers[len(layers)]\n",
    "  for i in outputLayer:\n",
    "    err[i] = a[i] * (1 - a[i]) * (y - a[i])\n",
    "  \n",
    "  #find error for hidden layers\n",
    "  for i in reversed(layers):\n",
    "    #exclude input layer\n",
    "    if(i == 2):\n",
    "      return err\n",
    "    #layers: {1: [1, 2, 3], 2: [4, 5], 3: [6, 7], 4: [8]}\n",
    "    current = layers[i] #starts with 4 = 4 = 4:[8]\n",
    "    prevous = layers[i-1] #starts with 4-1 = 3 = 3:[6,7]\n",
    "    for prevNode in prevous:\n",
    "      sumOfWeightAndError = 0\n",
    "      for currNode in current:\n",
    "        index =  int(str(prevNode) + str(currNode)) #link between two nodes\n",
    "        if index in w and currNode in err:\n",
    "          sumOfWeightAndError = sumOfWeightAndError + (w[index] * err[currNode])\n",
    "      err[prevNode] = a[currNode] * (1 - a[currNode]) * sumOfWeightAndError\n",
    "    return err\n",
    "errors = findError(layers, weights, a, y)\n",
    "print(\"\\n\\nBackward Propagation Find Error result:\")\n",
    "print(\"Error:\", errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights: {14: 2.1, 15: 2.5, 24: -1.4, 25: 2.7, 34: -1.7, 35: -1.9, 46: -0.19870596402850915, 47: 2.289647712228073, 56: 3.803902770778352, 57: 2.268777833773181, 68: 0.38678352361129403, 78: -2.31202053580199}\n",
      "Updated bios/theta: {1: 3.9, 2: -4.0, 3: 1.8, 4: 2.2, 5: -1.8, 6: -0.1960739061741223, 7: 1.0685912493929783, 8: 3.6893741780838423}\n"
     ]
    }
   ],
   "source": [
    "#backward propogation: calculate/Update Weights and Bios depending on error \n",
    "def backwordPropUpdateWeights(layers, w, l, err, a):\n",
    "  nWeight = {}\n",
    "  if(len(layers) <= 1):\n",
    "    return w\n",
    "  for i in range(len(layers)):\n",
    "    current = layers[i+1]\n",
    "    next = {}\n",
    "    if(i+2 in layers):\n",
    "      next = layers[i+2]\n",
    "    for currNode in current:\n",
    "      for nextNode in next:\n",
    "        index =  int(str(currNode) + str(nextNode)) #link between two nodes\n",
    "        #print(index)\n",
    "        if(nextNode not in err):\n",
    "            err[nextNode] = 0\n",
    "        if(currNode not in a):\n",
    "            a[currNode] = 0\n",
    "        nWeight[index] = w[index] + (l * err[nextNode] * a[currNode]) \n",
    "  return nWeight\n",
    "new_weights = backwordPropUpdateWeights(layers, weights, learning_rate, errors, a)\n",
    "print(\"Updated weights:\", new_weights)\n",
    "\n",
    "def backwordPropUpdateBios(b, l, err):\n",
    "  nBios = {}\n",
    "  for i in b:\n",
    "    if(i not in err):\n",
    "      err[i] = 0\n",
    "    nBios[i] = b[i] + (l * err[i])\n",
    "  return nBios\n",
    "\n",
    "new_bios = backwordPropUpdateBios(bios, learning_rate, errors)\n",
    "print(\"Updated bios/theta:\", new_bios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
